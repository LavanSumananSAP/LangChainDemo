{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LangChain\n",
    "\n",
    "## Motivation\n",
    "- LLM applications can be difficult to build and manage\n",
    "- LangChain provides a framework for building modular components and chaining them together to produce an LLM app\n",
    "- LangChain also provides plenty example apps and tools for connecting to various components (e.g. databases)\n",
    "- LangServe and LangSmith are additional tools for exposing an LLM app as a REST API and testing/debugging/monitoring respectively\n",
    "\n",
    "## Use Cases\n",
    "- Document question answering\n",
    "- Chatbots\n",
    "- Analyzing structured data\n",
    "\n",
    "## This Demo\n",
    "We'll create a simple app that generates the correct SQL for a given question, given context on a database, using LangChain.\n",
    "\n",
    "## Pre-requisites\n",
    "- OpenAI account + API key\n",
    "- Python 3, pip/pip3, jupyter notebook runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step One: Create LLM Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Note: run `pip install -r requirements.txt` to configure packages. Latest openai version is not compatible with langchain yet so we use v0.28.1\n",
    "\n",
    "# \"OpenAI\" and \"ChatOpenAI\" are essentially config objects (can specify temperature and other parameters)\n",
    "llm = OpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "chat_model = ChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SELECT name FROM employees;\n",
      "content='To get the names of every employee, you would use the following SQL query:\\n\\nSELECT name FROM employees;'\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"What SQL would you use to get the names of every employee?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "print(llm.invoke(text))\n",
    "print(chat_model.invoke(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Two: Create Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\"Given a database with the following table schemas: {schemas}, give me the SQL for the following request: {request}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Three: Create Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT FIRSTNAME FROM EMPLOYEES\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class LowercaseOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to all uppercase.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.upper()\n",
    "\n",
    "print(LowercaseOutputParser().parse(\"select firstname from employees\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Four: Chain Them Together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO FIND ALL ORDERS BY A CUSTOMER NAMED \"JOHN A SMITH\" FROM THE GIVEN DATABASE TABLES, YOU CAN USE THE FOLLOWING SQL QUERY:\n",
      "\n",
      "SELECT O.ORDERID\n",
      "FROM ORDERS O\n",
      "JOIN CUSTOMERS C ON O.CUSTOMERID = C.CUSTOMERID\n",
      "WHERE C.FIRSTNAME = 'JOHN' AND C.MIDINIT = 'A' AND C.LASTNAME = 'SMITH';\n"
     ]
    }
   ],
   "source": [
    "employeesSchema = \"\"\"CREATE TABLE EMPLOYEES\n",
    "      (EMPLOYEEID  CHAR(6)         NOT NULL,\n",
    "       FIRSTNAME   VARCHAR(12)     NOT NULL,\n",
    "       MIDINIT     CHAR(1)         NOT NULL,\n",
    "       LASTNAME    VARCHAR(15)     NOT NULL,\n",
    "       WORKDEPT    CHAR(3)                 ,\n",
    "       PHONENO     CHAR(4)                 ,\n",
    "       HIREDATE    DATE                    ,\n",
    "       JOB         CHAR(8)                 ,\n",
    "       EDLEVEL     SMALLINT        NOT NULL,\n",
    "       SEX         CHAR(1)                 ,\n",
    "       BIRTHDATE   DATE                    ,\n",
    "       SALARY      DECIMAL(9,2)            ,\n",
    "       BONUS       DECIMAL(9,2)            ,\n",
    "       COMM        DECIMAL(9,2)         \n",
    "       PRIMARY KEY (EMPLOYEEID))\n",
    "\"\"\"\n",
    "\n",
    "customersSchema = \"\"\"CREATE TABLE CUSTOMERS\n",
    "      (CUSTOMERID  VARCHAR(12)     NOT NULL,\n",
    "       FIRSTNAME   VARCHAR(12)     NOT NULL,\n",
    "       MIDINIT     CHAR(1)         NOT NULL,\n",
    "       LASTNAME    VARCHAR(15)     NOT NULL,\n",
    "       STOREID     VARCHAR(15)             ,\n",
    "       PHONENO     VARCHAR(12)             ,\n",
    "       ACTIVE      BOOLEAN                 ,\n",
    "       PRIMARY KEY (CUSTOMERID))\n",
    "\"\"\"\n",
    "\n",
    "ordersSchema = \"\"\"CREATE TABLE ORDERS\n",
    "      (ORDERID     VARCHAR(12)      NOT NULL,\n",
    "       CUSTOMERID  CHAR(12)                 ,\n",
    "       PRIMARY KEY (ORDERID)                ,\n",
    "       FOREIGN KEY (CUSTOMERID) REFERENCES CUSTOMERS(CUSTOMERID))        \n",
    "\"\"\"\n",
    "\n",
    "schemas = employeesSchema + customersSchema + ordersSchema\n",
    "\n",
    "request = input(\"What is your request?\")\n",
    "\n",
    "chain = prompt | chat_model | LowercaseOutputParser()\n",
    "\n",
    "# Example calls:\n",
    "# find the storeid of a customer named \"John A Smith\"\n",
    "# find all orders by a customer named \"John A Smith\"\n",
    "# get the full name and salaries of employees in the sales department ordered by education level\n",
    "\n",
    "print(chain.invoke({\"schema\": schemas, \"request\": request}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Currently, prompt takes in all table schemas in a database, which will cause problems at enterprise scale. Various solutions can be implemented to filter for relevant schemas; one such solution is using example selectors and running a similarity search on a vector store of example schemas to find relevant tables based on the request (see https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/similarity)\n",
    "- Many prompt templates are provided in the LangChain community (example https://smith.langchain.com/hub/rlm/text-to-sql)\n",
    "- Expose the app to consumers as a REST API with LangServe\n",
    "- Test, debug, and monitor the app with LangSmith"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
